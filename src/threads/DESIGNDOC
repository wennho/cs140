			+--------------------+
			| CS 140             |
			| PROJECT 1: THREADS |
			| DESIGN DOCUMENT    |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Wen Hao Lui <whlui@stanford.edu>
Solomon Sia <solomon5@stanford.edu>
Gavin Bird <gbird@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Within struct thread, num_ticks_to_sleep is decremented and tells
if a thread is sleeping, and whether it is time to wake the thread. */

struct thread
  {
    int64_t num_ticks_to_sleep;         /* Ticks remaining to sleep. */
  };

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

First, we check if the timer_sleep was called with a positive number,
and if it wasn't then we return immediately. Then, we disable the interrupt
handler, set a field on the thread (num_ticks_to_sleep) which records
how many ticks the thread is to sleep, and block the thread. At the
end of the function the interrupt level is set back to its original, 
as this is only reach when the thread is unblocked again.

In the timer tick interrupt handler, we call a function in which we decrement
the variable num_ticks_to_sleep and check whether it has reached zero. If so,
we wake the thread. We return immediately before decrementing if the value of
num_ticks_to_sleep is negative or zero, because any thread that has not gone
to sleep should have a value of zero for that variable. 

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The only calculation we do in there is to decrement the number of ticks
remaining to sleep for all sleeping threads, which is a very fast operation.
For all of the calculations relating to the mlfqs scheduler, we wrote another
function and created a thread which would always have maximum priority
(PRI_MAX + 1) to be notified to run that function every timer tick by being
notified by a semaphore.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

We disable interrupts before calling thread_block, which prevents multiple
threads from calling at the same time. The other things called only affect
thread specific variables or perform reads, which means we can't have 
race conditions.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Same as above.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

This design ensures that we do little work in the timer_interrupt itself,
which makes sure that we don't erroneously calculate threads priorities
based on work done in that. It also modified and added only a few functions
to the file while adding all of the necessary functionality, so it is not
very complex and should be relatively easy to maintain.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In struct thread:
    /* List of all locks held by the thread */
    struct list lock_list;              
    
    /* Lock we are in process of acquiring, used for recursive priority 
    donation */
    struct lock* lock_blocked_by;       
    
    int original_priority; /* Original base priority. */

In struct lock:
    struct list_elem elem;   /* enables locks to be included in lists */
    
    
>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Each thread has a pointer to the lock that causes it to block. Each lock also 
has a pointer to the thread holding the lock (if there is one). 
 
thread A -> lock 1 -> thread B -> lock 2 -> thread C

For example, in the above set up, thread C (priority 30) holds lock 2 and 
thread B (priority 31) holds lock 1. We have thread B trying to acquire 
lock 2 and thread A trying to acquire lock 1, hence pointers from each thread 
to the respective locks. 


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

Since both locks and condition variables are based on semaphores, we only need 
to do the check for the underlying semaphore. When signaling the semaphore, we
look at all threads waiting on the semaphore and wake up the thread with the
highest priority.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

When a thread tries to acquire a lock, it first checks to see if the lock is 
already held by another thread. If so, it calls the recursive priority donation
function priority_donate, which operates as follows:

If the caller thread A has higher priority than the lock holder thread B, we 
upgrade the priority of B to that of A. We then check to see if the lock holder 
thread is also waiting on a lock held by another thread C. If so, we call the 
priority donation function again, but with thread B set as the caller thread 
and thread C set as the thread holding the other lock.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

When lock_release is called, we first remove the lock from the list of locks
the current thread is holding. In the underlying semaphore sema_up, we then 
iterate through all threads waiting on the semaphore and unblock the highest 
priority thread. 

The thread then calls thread_reset_priority_and_yield, which iterates through 
the list of lock the thread still holds, and recalculates its priority by taking
the max priority out of all the threads waiting on all the locks it holds, and 
its own base priority. 

Finally, the thread yields to the highest-priority ready thread.


---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

When we call thread_set_priority, the calculated priority also depends on the 
priority of threads that are waiting on the locks the current thread has 
acquired due to priority donation. However, these other priorities may change 
due to priority donations from other threads that in turn want to acquire these 
locks. 

Hence, a nested priority donation to the current thread might be occurring at 
the same time that thread_set_priority is being called. thread_set_priority 
would then be using the old waiting thread priorities when setting its own
priority, which is wrong.

We avoid this situation by ensuring interrupts are disabled when calling both 
thread_set_priority and priority_donate. This ensures mutual exclusion.


---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose to have an unsorted list of threads instead of maintaining a list of
threads sorted by priority. This is because a sorted list takes a lot more 
overhead to maintain, especially with nested priority donations and in the 
subsequent mlfqs scheduler. In order to reduce code complexity and reduce 
processing overhead, we decided to use the current approach. 


			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Scheduling. */
#define TIME_SLICE 4            /* # of timer ticks to give each thread. */
static unsigned thread_ticks; /* # of timer ticks since last yield. */
static fixed_point_t load_avg; /* Load average on CPU. */

/* Within struct thread, included the niceness integer that keeps track of
a thread's niceness.*/
/* included the recent cpu fixed point so we can calculate priority */

struct thread
  {

    int niceness;                       /* Niceness. */
    fixed_point_t recent_cpu;           /* Recent cpu usage for thread. */
 }

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0		0	0	0	63	61	59		A
 4		4	0	0	62	61	59		A
 8		8	0	0	61	61	59		B
12		8	4	0	61	60	59		A
16		12	4	0	60	60	59		B
20		12	8	0	60	59	59		A
24		16	8	0	59	59	59		B
28		16	12	0	59	58	59		A
32		20	12	0	58	58	59		C
36		20	12	4	58	58	58		A

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

When two threads which have not run have the same (highest) priority, it is not 
clear which thread to run, so we simply run the thread that was created first. 
This matches the behavior of the scheduler.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

Scheduling code inside interrupt context unfairly penalizes threads that were 
interrupted since the CPU load for the thread would increase while the thread 
did no useful work. These threads would then have lower priorities than they 
deserve and there would be an unfair distribution of CPU time. By having 
most of the scheduling code in a dedicated thread outside interrupt context, we 
ensure each thread is only penalized for the CPU time it uses, and thus have a 
fairer allocation of CPU time.  

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

If we had time, we would find a way to speed up computation of
priority checking, priority donation and thread switching.

Possible optimizations might include sorting the list constantly
instead of having to frequently check for the max value of priorities
waiting to run.


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

No, it was just right.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

Everything was useful!

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

No, the assignment description was very helpful, thanks!

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

Don't know, we didn't use the TAs.

>> Any other comments?

Nope.